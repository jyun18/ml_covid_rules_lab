{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prism Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../datasets/covid_categorical_good.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_of_attribute(attributes, target): # gets the index of the 'target' value in the 'attributes' list\n",
    "#     start = 0\n",
    "#     end = len(attributes) - 1\n",
    "\n",
    "#     while start <= end: \n",
    "#         middle = (start + end)/ 2\n",
    "#         midpoint = attributes[middle]\n",
    "#         if midpoint > target:\n",
    "#             end = middle - 1\n",
    "#         elif midpoint < target:\n",
    "#             start = middle + 1\n",
    "#         else:\n",
    "#             return midpoint\n",
    "    for i in range(len(attributes)):            \n",
    "        if target == attributes[i]:\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def get_attribute_at_index(attributes, index): # gets the value of the 'attributes' list at 'index'\n",
    "    return attributes[index]\n",
    "\n",
    "\n",
    "def construct_rule(dataset, class_label, attributes, acc_t, cov_t): # constructs and returns a rule\n",
    "    attr = sorted(attributes) # list of attributes (sorted, so I can binary search which is faster than linear search)\n",
    "    rule = [] \n",
    "    \n",
    "    attribute_value_pairs = []\n",
    "    \n",
    "    for i in range(len(attr) - 1): # for each attribute value \n",
    "        for data_entry in dataset: # for each data_entry in the dataset\n",
    "            if isinstance(data_entry[i], int) or isinstance(data_entry[i], float): # if attribute value of data_entry is numeric\n",
    "                potential_att_val_pair = [get_attribute_at_index(attr, i), data_entry[i], \">=\"]\n",
    "                if potential_att_val_pair not in attribute_value_pairs: # if potential attribute-value pair is not in our list\n",
    "                    attribute_value_pairs.append(potential_att_val_pair) # append the attribute-numeric value pair with >=\n",
    "                    attribute_value_pairs.append([get_attribute_at_index(attr, i), data_entry[i], \"<\"]) # append the attribute-numeric value pair with <\n",
    "            else:\n",
    "                potential_att_val_pair = [get_attribute_at_index(attr, i), data_entry[i]] # potential attribute-value pair is created\n",
    "                if potential_att_val_pair not in attribute_value_pairs: # if potential attribute-value pair is not in our list, then append it\n",
    "                    attribute_value_pairs.append(potential_att_val_pair)\n",
    "                    \n",
    "    max_acc = 0 # accuracy of the current rule\n",
    "    max_cov = 0 # coverage of the current rule\n",
    "    \n",
    "    while True:      \n",
    "        acc = [] # list that will contain the accuracy values of the current rule + every attribute-value pair\n",
    "        cov = [] # list that will contain the coverage values of the current rule + every attribute-value pair\n",
    "        \n",
    "        # calculates the accuracy and coverage of the current rule + every attribute-value pair \n",
    "        for attr_val_pair in attribute_value_pairs:\n",
    "            correct = 0 # number of persons where rule correctly classifies outcome\n",
    "            total = 0 # number of persons who fit the rule \n",
    "            temp_rule = rule[:] # deep copy of 'rule' list\n",
    "            if isinstance(attr_val_pair[1], int) or isinstance(attr_val_pair[1], float): \n",
    "                 temp_rule.append([get_index_of_attribute(attr, attr_val_pair[0]), attr_val_pair[1], attr_val_pair[2]]) # append an attribute-value pair to the prev. rule (where the value is numeric)\n",
    "            else: \n",
    "                temp_rule.append([get_index_of_attribute(attr, attr_val_pair[0]), attr_val_pair[1]]) # append an attribute-value pair to the previous rule\n",
    "            for i in range(len(dataset)):\n",
    "                count = 0 # keeps track of the number of attributes in each person correctly classified by temp_rule\n",
    "                for bools in temp_rule:\n",
    "                    if isinstance(bools[1], int) or isinstance(bools[1], float): # if attribute value is numeric\n",
    "                        if bools[2] == \">=\": # if the rule we're looking at is asking if the data entry's numeric attribute value is >= the rule's numeric value\n",
    "                            if dataset[i][bools[0]] >= bools[1]:\n",
    "                                count = count + 1 # if data_entry's numeric value is greater than or equal to our temp_rule's numeric value, then increment count\n",
    "                        else: # if the rule we're looking at is asking if the data entry's numeric attribute value is < the rule's numeric value\n",
    "                            if dataset[i][bools[0]] < bools[1]:\n",
    "                                count = count + 1 # if data_entry's numeric value is less than our temp_rule's numeric value, then increment count\n",
    "                    elif dataset[i][bools[0]] == bools[1]: \n",
    "                        count = count + 1 # if data_entry's attribute at bools[0] is correctly classified by temp_rule, then increment count\n",
    "                    \n",
    "                if count == len(temp_rule): # if temp_rule correctly classifies (on the data entry) every single attribute it contains\n",
    "                    if dataset[i][len(dataset[i]) - 1] == class_label: # as well as correctly classifying outcome\n",
    "                        correct = correct + 1 \n",
    "                        total = total + 1 # then increment correct and total counter\n",
    "                    else:\n",
    "                        total = total + 1 # else temp_rule is wrong about the outcome, so only increment total counter\n",
    "            if total == 0: # prevent division by 0\n",
    "                acc.append(0)\n",
    "                cov.append(0)\n",
    "            else:\n",
    "                acc.append(correct/total) # append temp_rule's accuracy to 'acc' list\n",
    "                cov.append(correct) # append temp_rule's coverage to 'cov' list\n",
    "                \n",
    "                \n",
    "        index = -1 # index of attribute with largest accuracy (as long as its coverage meets the coverage threshold)\n",
    "                    # initially set it to be -1\n",
    "        for i in range(len(acc)): \n",
    "            if acc[i] > max_acc:\n",
    "                if cov[i] > cov_t:\n",
    "                    max_acc = acc[i]\n",
    "                    max_cov = cov[i]\n",
    "                    index = i\n",
    "                    \n",
    "        if index == -1: # if 'index' still is -1, then that means no improvement can be made on the accuracy \n",
    "                        # of the old rule while retaining its coverage to be greater than the coverage threshold\n",
    "                \n",
    "            return rule, max_acc, max_cov, class_label # so just return \n",
    "        \n",
    "        elif max_acc < acc_t: # if \"max_acc\", ie the accuracy of the best newly generated rule, falls below the accuracy threshold\n",
    "            return rule, max_acc, max_cov, class_label # just return \n",
    "        \n",
    "        else: # else, there might be still room for improvement on our rule, so\n",
    "            best_att_val_pair = attribute_value_pairs[index] \n",
    "            if isinstance(best_att_val_pair[1], int) or isinstance(best_att_val_pair[1], float): \n",
    "                rule.append([get_index_of_attribute(attr, best_att_val_pair[0]), best_att_val_pair[1], best_att_val_pair[2]]) # update rule(where the value is numeric)\n",
    "            else: \n",
    "                rule.append([get_index_of_attribute(attr, best_att_val_pair[0]), best_att_val_pair[1]]) # update rule where value isn't numeric\n",
    "            attribute_value_pairs.remove(best_att_val_pair) # delete attribute-value pair from the list since its now in our rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prism(col_headers, data, acc_thresh, cov_thresh):\n",
    "    rules = [] # rules\n",
    "    acc_and_cov = [] # accuracy and coverage of our rules\n",
    "    final_class_labels = [] # what the RHS of our rules are (either alive or dead)\n",
    "    c_data = data\n",
    "    class_labels = ['alive'] # targetted class label(s)\n",
    "    \n",
    "    while len(c_data) >= cov_thresh: # while it is still possible for a non-empty rule to be generated\n",
    "        for class_label in class_labels:\n",
    "            rule, acc, cov, cls_label = construct_rule(c_data, class_label, col_headers, acc_thresh, cov_thresh)\n",
    "            rules.append(rule)\n",
    "            acc_and_cov.append([acc, cov])\n",
    "            final_class_labels.append(cls_label)\n",
    "                \n",
    "            to_remove = [] # indicies of 'c_data' that our rule covers, so we want to remove these persons from the dataset\n",
    "            for i in range(len(c_data)): # find the people in 'c_data' that our rule correctly classifies\n",
    "                count = 0\n",
    "                for bools in rule:\n",
    "                    if isinstance(bools[1], int) or isinstance(bools[1], float): # if attribute value is numeric\n",
    "                        if bools[2] == \">=\": # if the rule we're looking at is asking if the data entry's numeric attribute value is >= the rule's numeric value\n",
    "                            if c_data[i][bools[0]] >= bools[1]:\n",
    "                                count = count + 1 # if data_entry's numeric value is greater than or equal to our temp_rule's numeric value, then increment count\n",
    "                        else: # if the rule we're looking at is asking if the data entry's numeric attribute value is < the rule's numeric value\n",
    "                            if c_data[i][bools[0]] < bools[1]:\n",
    "                                count = count + 1 # if data_entry's numeric value is less than our temp_rule's numeric value, then increment count\n",
    "                    elif c_data[i][bools[0]] == bools[1]:\n",
    "                        count = count + 1    \n",
    "                    \n",
    "                if count == len(rule):\n",
    "                    to_remove.append(i)\n",
    "\n",
    "            for x in to_remove:\n",
    "                c_data[x] = 0\n",
    "\n",
    "            c_data = [s for s in c_data if s != 0] # remove the people that our rule correctly classifies\n",
    "            \n",
    "            if(len(c_data) == 0): # break out of for loop if the dataset's length = 0\n",
    "                break\n",
    "    \n",
    "    for rule in rules:\n",
    "        for x in rule:\n",
    "            index = x[0]\n",
    "            x[0] = get_attribute_at_index(col_headers, index) # make output look more readable\n",
    "            \n",
    "    return rules, acc_and_cov, final_class_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(data_file)\n",
    "data = data.dropna(how=\"any\")\n",
    "data_rows = data.to_numpy().tolist()\n",
    "columns_list = data.columns.to_numpy().tolist()\n",
    "\n",
    "rules, accuracy_and_coverage, target_class_label = prism(columns_list, data_rows, 0.7, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule:  [['age', 34, '<'], ['hypertension', 'no'], ['diabetes', 'no'], ['age', 6, '>='], ['copd', 'no']] , accuracy and coverage:  [0.988745409311693, 50076] , targeted class label:  alive\n",
      "rule:  [['age', 44, '<'], ['renal_chronic', 'no'], ['imm_supr', 'no']] , accuracy and coverage:  [0.9608285676032362, 50235] , targeted class label:  alive\n",
      "rule:  [['age', 56, '<'], ['copd', 'no'], ['age', 34, '>=']] , accuracy and coverage:  [0.8890111840937334, 50078] , targeted class label:  alive\n",
      "rule:  [] , accuracy and coverage:  [0, 0] , targeted class label:  alive\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rules)):\n",
    "    print(\"rule: \", rules[i], \", accuracy and coverage: \", accuracy_and_coverage[i], \", targeted class label: \", target_class_label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Depending on the accuracy and coverage threshold you set, you get different rules. But most of the time, these rules followed my intuition, which is that if you do not suffer from any other chronic illnesses and you are young, then the liklihood of you dying is very minimal. For example, with a coverage threshold of 50,000 and an accuracy threshold of 0.7, I found that the top rule (with an accuracy of 0.9887 and a coverage of 50076), was that below the age of 34, and don't have hypertension, don't have diabetes, and don't have copd. This makes sense to me, and follows my intuition, as I know from the news and everything that if you don't suffer from any prior medical problems, covid most likely won't kill you. \n",
    "    \n",
    "I also found it interesting that if I set the outcome as 'dead', then no rules with decent accuracy and coverage are generated, implying that covid deaths stem from a variety of reasons (since no single rule can predict, with a high accuracy, your death). \n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
